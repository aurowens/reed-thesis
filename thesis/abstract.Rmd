Random forests are powerful predictive models but there is not a built-in method for statistical inference within these models. This paper compares several of the most common methods of performing inference on random forests while presenting a new method, INFFOREST variable importance. On simulated data with multicolinearity, the INFFOREST method is  able to show significance for four out of five predictors used to generate the response. Existing methods are tested and performed similarly on the simulated data set. INFFOREST variable importance allows claims to be made about the relationship between a predictor and the response, in the context of the rest of the variables in the model. This sets it apart from the exiting methods and creates some interesting implications.\par

