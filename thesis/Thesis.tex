% This is the Reed College LaTeX thesis template. Most of the work
% for the document class was done by Sam Noble (SN), as well as this
% template. Later comments etc. by Ben Salzberg (BTS). Additional
% restructuring and APA support by Jess Youngberg (JY).
% Your comments and suggestions are more than welcome; please email
% them to cus@reed.edu
%
% See http://web.reed.edu/cis/help/latex.html for help. There are a
% great bunch of help pages there, with notes on
% getting started, bibtex, etc. Go there and read it if you're not
% already familiar with LaTeX.
%
% Any line that starts with a percent symbol is a comment.
% They won't show up in the document, and are useful for notes
% to yourself and explaining commands.
% Commenting also removes a line from the document;
% very handy for troubleshooting problems. -BTS

% As far as I know, this follows the requirements laid out in
% the 2002-2003 Senior Handbook. Ask a librarian to check the
% document before binding. -SN

%%
%% Preamble
%%
% \documentclass{<something>} must begin each LaTeX document
\documentclass[12pt,twoside]{reedthesis}
% Packages are extensions to the basic LaTeX functions. Whatever you
% want to typeset, there is probably a package out there for it.
% Chemistry (chemtex), screenplays, you name it.
% Check out CTAN to see: http://www.ctan.org/
%%
\usepackage{graphicx,latexsym}
\usepackage{amsmath}
\usepackage{amssymb,amsthm}
\usepackage{longtable,booktabs,setspace}
\usepackage{chemarr} %% Useful for one reaction arrow, useless if you're not a chem major
\usepackage[hyphens]{url}
% Added by CII
\usepackage{hyperref}
\usepackage{lmodern}
% End of CII addition
\usepackage{rotating}

% Next line commented out by CII
%%% \usepackage{natbib}
% Comment out the natbib line above and uncomment the following two lines to use the new 
% biblatex-chicago style, for Chicago A. Also make some changes at the end where the 
% bibliography is included. 
%\usepackage{biblatex-chicago}
%\bibliography{thesis}


% Added by CII (Thanks, Hadley!)
% Use ref for internal links
\renewcommand{\hyperref}[2][???]{\autoref{#1}}
\def\chapterautorefname{Chapter}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Subsection}
% End of CII addition

% Added by CII 
\usepackage{caption}
\captionsetup{width=5in}
% End of CII addition

% \usepackage{times} % other fonts are available like times, bookman, charter, palatino


% To pass between YAML and LaTeX the dollar signs are added by CII
\title{Statistical Inference on Random Forests}
\author{Aurora Owens}
% The month and year that you submit your FINAL draft TO THE LIBRARY (May or December)
\date{May 2017}
\division{Mathematics and Natural Sciences}
\advisor{Andrew Bray}
%If you have two advisors for some reason, you can use the following
% Uncommented out by CII
% End of CII addition

%%% Remember to use the correct department!
\department{Mathematics}
% if you're writing a thesis in an interdisciplinary major,
% uncomment the line below and change the text as appropriate.
% check the Senior Handbook if unsure.
%\thedivisionof{The Established Interdisciplinary Committee for}
% if you want the approval page to say "Approved for the Committee",
% uncomment the next line
%\approvedforthe{Committee}

% Added by CII
%%% Copied from knitr
%% maxwidth is the original width if it's less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\renewcommand{\contentsname}{Table of Contents}
% End of CII addition

\setlength{\parskip}{0pt}

% Added by CII

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\Acknowledgements{
I want to thank a few people.
}

\Dedication{
You can have a dedication here if you wish.
}

\Preface{
This is an example of a thesis setup to use the reed thesis document
class.
}

\Abstract{
The preface pretty much says it all. \par  Second paragraph of abstract
starts here.
}

% End of CII addition
%%
%% End Preamble
%%
%

\begin{document}

% Everything below added by CII
      \maketitle
  
  \frontmatter % this stuff will be roman-numbered
  \pagestyle{empty} % this removes page numbers from the frontmatter

      \begin{acknowledgements}
      I want to thank a few people.
    \end{acknowledgements}
  
      \begin{preface}
      This is an example of a thesis setup to use the reed thesis document
      class.
    \end{preface}
  
      \hypersetup{linkcolor=black}
    \setcounter{tocdepth}{2}
    \tableofcontents
  
      \listoftables
  
      \listoffigures
  
      \begin{abstract}
      The preface pretty much says it all. \par  Second paragraph of abstract
      starts here.
    \end{abstract}
  
      \begin{dedication}
      You can have a dedication here if you wish.
    \end{dedication}
  
  \mainmatter % here the regular arabic numbering starts
  \pagestyle{fancyplain} % turns page numbering back on

  \chapter*{Introduction}\label{introduction}
  \addcontentsline{toc}{chapter}{Introduction}
  
  Welcome to the \emph{R Markdown} thesis template. This template is based
  on (and in many places copied directly from) the \LaTeX~template, but
  hopefully it will provide a nicer interface for those that have never
  used \TeX~or \LaTeX~before. Using \emph{R Markdown} will also allow you
  to easily keep track of your analyses in \textbf{R} chunks of code, with
  the resulting plots and output included as well. The hope is this
  \emph{R Markdown} template gets you in the habit of doing reproducible
  research, which benefits you long-term as a researcher, but also will
  greatly help anyone that is trying to reproduce or build onto your
  results down the road.
  
  Hopefully, you won't have much of a learning period to go through and
  you will reap the benefits of a nicely formatted thesis. The use of
  \LaTeX~in combination with \emph{Markdown} is more consistent than the
  output of a word processor, much less prone to corruption or crashing,
  and the resulting file is smaller than a Word file. While you may have
  never had problems using Word in the past, your thesis is likely going
  to be about twice as large and complex as anything you've written
  before, taxing Word's capabilities. After working with \emph{Markdown}
  and \textbf{R} together for a few weeks, we are confident this will be
  your reporting style of choice going forward.
  
  \subsubsection{Why use it?}\label{why-use-it}
  
  \emph{R Markdown} creates a simple and straightforward way to interface
  with the beauty of \LaTeX. Packages have been written in \textbf{R} to
  work directly with \LaTeX~to produce nicely formatting tables and
  paragraphs. In addition to creating a user friendly interface to \LaTeX,
  \emph{R Markdown} also allows you to read in your data, to analyze it
  and to visualize it using \textbf{R} functions, and also to provide the
  documentation and commentary on the results of your project. Further, it
  allows for \textbf{R} results to be passed inline to the commentary of
  your results. You'll see more on this later.
  
  \subsubsection{Who should use it?}\label{who-should-use-it}
  
  Anyone who needs to use data analysis, math, tables, a lot of figures,
  complex cross-references, or who just cares about the final appearance
  of their document should use \emph{R Markdown}. Of particular use should
  be anyone in the sciences, but the user-friendly nature of
  \emph{Markdown} and its ability to keep track of and easily include
  figures, automatically generate a table of contents, index, references,
  table of figures, etc. should make it of great benefit to nearly anyone
  writing a thesis project.
  
  \section{Trees and Random Forests}\label{trees-and-random-forests}
  
  \subsection{Trees}\label{trees}
  
  ~~~~~Decision trees may be familiar to many with a background in the
  social or medical sciences as convenient ways to represent data and can
  assist in decision making. Morgan and Sonquist (1963) derived a way for
  constructing trees motivated by the specific feature space of data
  collected from interviews and surveys. Unlike, say agricultural data
  which involves mostly numerical variables like rainfall, the data
  collected from interviews is mostly categorical. On top of this issue,
  the datasets Morgan and Sonquist dealt with had few participants,
  \emph{n}, and much data collected on them, \emph{p}. To continue with
  their list of difficulties, there was reason to believe that there were
  lurking errors in the variables that would be hard identify and
  quantify. Lastly, many of the predictors were correlated and Morgan and
  Sonquist doubted that the additive assumptions of many models would be
  appropriate for this data. Morgan and Sonquist noted that while many
  statistical methods would have a difficulty accurately parsing this
  data, a clever researcher with quite a lot of time could create a
  suitable model simply by grouping values in the feature space and
  predicting that the response corresponding to these values would be the
  mean of the observed responses given the grouped conditions. Their
  formalization of this procedure in terms of ``decision rules'' laid the
  ground work for future research on decision trees.
  
  ~~~~~Later researchers proposed new methods for creating trees that
  improved upon the Morgan and Sonquist model. Leo Breiman et al 1984
  proposed an algorithm called CART, \emph{classification and regression
  trees}, that would allow trees to be fit on various types of data. An
  alternative to this method is conditional inference trees. Torsten
  Hothorn, Kurt Hornik, Achim Zeileis argue in their 2006 paper
  \textbf{Unbiased Recursive Partitioning: A Conditional Inference
  Framework}, CART has a selection bias toward variables with either
  missing values or a great number of possible splits. This bias can
  effect the interpretability of all tree models fit using this method. As
  an alternative to CART and other algorithms, Hothorn et al propose a new
  method, conditional inference trees.
  
  ~~~~~ There is a limit to the predictive capabilities of a single tree
  as they suffer from high variance. To alleviate this, random forests are
  often used instead. They function by enlisting the help of many trees,
  and then by aggregating the responses over all of them but with a subtle
  trick that ensures the trees will be independent of each other. At each
  split only \emph{m} variables are considered as possible candidates.
  
  \section{What We Mean When We Talk About
  Inference}\label{what-we-mean-when-we-talk-about-inference}
  
  \subsection{Inferential vs Descriptive
  Statistics}\label{inferential-vs-descriptive-statistics}
  
  ~~~~~ A note should be made of the difference between inferential and
  descriptive statistics. This paper's aim is to describe a process of
  making inferential claims using random forests, not descriptive ones.
  Descriptive statistics describe the data at hand without making any
  reference to a larger data generating system that they come from. It
  follows that inferential statistics then make claims about the data
  generating system given the data at hand.
  
  ---Frequentist vs Bayesian---
  
  ~~~~~ ---There is some debate about interpreting inferential statistics.
  On one hand, we have the Bayesian model---
  
  \emph{Need a better way to discuss inference than Bayes/frequentist}
  
  \section{Permutations and
  Populations}\label{permutations-and-populations}
  
  ~~~~~ As stated in the introduction of the \textbf{Chronical of
  Permutations Statistical Methods} by KJ Berry et al, 2014, there are two
  models of statistical inference. One is the population model, where we
  assume that the data was randomly sampled from one (or more)
  populations. Under this model, we assume that the data generated follows
  some known distribution. ``Under the population model, the level of
  statistical significance that results from applying a statistical test
  to the results of an experiment or a survey corresponds to the frequency
  with which the null hypothesis would be rejected in repeated random
  samplings from the same specified population(s)'', (Berry et al, 2014).
  
  ~~~~~The permutation family of methods, on the other hand, only assumes
  that the observed result was caused by experimental variability. The
  test statistics is first calculated for the observed data, then the data
  is permuted a number of times. The statistic is calculated after each
  permutation to dervive a distribution of possible values. Then the
  original test statistic is tested against this distribution. If it is
  exceptionally rare, then there is evidence that our observation was not
  simply experimental variability.
  
  \section{Inference on Random Forests}\label{inference-on-random-forests}
  
  \subsection{The Problem}\label{the-problem}
  
  ~~~~~Random forests create models with great predictive-, but poor
  inferential capabilities. After Morgan and Sonquist initial development
  of decision trees, they quickly moved to the domain of machine learning
  and away from statistics, thus, researchers focused on bettering
  predictions and improving run times and less on the statistics behind
  them. Inferential statistics with random forests is usually treated as a
  variable selection problem, and generally falls behind the predictions
  in importance. This has limited the applications of random forests in
  certain fields, as to many the question of ``why'' the data is the way
  it is, is just, if not more, important as the predictions. There are
  several means of performing descriptive statistics with random forests
  that could be interpreted incorrectly as attempting to answer this,
  namely base variable importance, but without a statistically backed
  method for performing variable importance, the use of random forest is
  limited to prediction-only settings.
  
  \subsection{Proposed solutions to this
  problem}\label{proposed-solutions-to-this-problem}
  
  ~~~~~Statisticians Breiman and Cutler proposed a method of permuted
  variable importance to answer this problem. Their method compares the
  variable importance for each variable in a tree-wise manner. For each
  tree, the permuted variable importance of the variable \(X_j\) is:
  
  \[PV^t(x_j) = \frac{\sum_{i \in |B|} {y} - \hat{y}^t}{|B|} - \frac{\sum_{i \in |*B|} {y} - \hat{*y}^t}{|*B|} \]
  
  ~~~~~ Where \(B\) is the matrix representing the feature space, \(|B|\)
  is the number of observations, \(*B\) is the matrix of predictors but
  with \(X_j\) permuted, \(\hat{y}\) is the predicted outcome, and
  \(\hat{*y}^t\) is the predicted outcomes after variable \(X_j\) has been
  permuted. This value is averaged over all the trees. It's important to
  note that if the variable \(X_j\) is not split on in the tree \(t\), the
  tree-wise variable importance will be 0.
  
  ~~~~~ Creating a permutation-based method is certainly an attractive
  solution to our problem. One, it allows us to estimate the distribution
  of variable importance and generate a Z score under the null hypothesis
  that \(PV = 0\).
  
  \[PV(x_j) = \frac{\sum_1^ntree PV^t(x_j)}{\frac{\hat{\sigma}}{\sqrt{ntree}}}\]
  
  ~~~~~ Strobl et al from the University of Munich criticize this method
  in their 2008 technical report, \textbf{Danger: High Power! -- Exploring
  the Statistical Properties of a Test for Random Forest Variable
  Importance}. One, this method has the downside of increasing power with
  increasing numbers of trees in the forest. This is a more or less
  arbitrary parameter which we would hope would not affect our importance
  estimates. Secondly, the null hypothesis under Breiman and Cutler's
  strategy is that the variable importance \(V\) for any variable \(X_j\)
  is not equal to zero given \(Y\), the response. Because random forests
  are most often used in situations with multicolinearity that would make
  other methods like the linear model difficult, Strobl argues that any
  variable importance measure worth its salt should not be mislead by
  correlation within the predictors.
  
  ~~~~~ The researchers at the University of Munich published a fully
  fleshed response to the Breiman and Cutler method in 2008, titled
  \emph{Conditional Variable Importance for Random Forests} that address
  these issues. Strobl et al propose restructuring the Breiman and Cutler
  algorithm to account for conditional dependence among the predictors.
  Their algorithm looks like this:
  
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Fit a random forest to the model, \(R_0\), and calculate base variable
    importance for each variable \(V\)
  \item
    For every predictor \(X_j \in X_1,...,X_n\):
  \end{enumerate}
  
  \begin{itemize}
  \tightlist
  \item
    2a. Conditionally permute \(X_j\) given the splits found in \(R_0\)
  \item
    2b. Fit a new random forest \(R_j\) with the permuted data
  \item
    2c. Calculate a new variable importance \(\hat{V}_j\)
  \end{itemize}
  
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{2}
  \tightlist
  \item
    For every variable \(X_1,..., X_n\), \[CV(X_j) = \hat{V}_j - V_j\]
  \end{enumerate}
  
  ~~~~~ The null hypothesis is that \(CV(X_j) = 0\) given the predictor
  \(Y\) \emph{and all other predictors} \(X_1,..X_n\).This accounts for
  interactions between \(X_j\) and the other predictors. Using the
  simulated data from the previous example, here's an implementation of
  the algorithm outlined here as it is in the \texttt{party} package.
  
  ~~~~~This paper aims to provide a response to this method. One the
  conditional permutation algorithm is notoriously slow with any dataset
  of a size that is appropriate for a random forest. Two, the partitions
  are made from the random forest corresponding to the formula of
  \(Y~X_1,...,X_n\) instead of a model of \(X_j~X_1,...,X_n\).
  
  \chapter{Simulations and Comparisons}\label{simulations-and-comparisons}
  
  In 1984, Breiman et al introduces a revolutionary new algorithm for
  trees. \textbf{Need to acquire} \emph{Classification and Regression
  Trees} \textbf{to make sure the method discused in MASS is the same that
  Breiman uses/is used in} \texttt{randomForest}
  
  \textbf{Tree Algorithm} CART?
  
  Begin by considering the entire feature space \(X_1, ..., X_n\). Then:
  
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
    Consider every possible pair of partitions of this feature space,
    \(P_1, P_2\), so that if \(X_1 = x_1 , X_2 = x_2,..., X_n = x_n\)
    where \({x_1,...,x_n} \in P_1\) then our prediction is the mean value
    of \(y\) given \(x_1,..,x_n \in P_1\).
  \item
    Choose the partitions that minimize RSS
  \item
    For each new partition, repeat steps 1 and 2 until some stopping
    condition is reached.
  \end{enumerate}
  
  CI trees 1. For case weights \(w\) test the global null hypothesis of
  independence between any of the m covariates and the response. Stop if
  this hypothesis cannot be rejected. Otherwise select the \(j_{th}\)
  covariate \(Xj\) with strongest association to \(Y\).
  
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{1}
  \item
    Choose a set \(A \subset X_{j}\) in order to split \(X_{j}\) into two
    disjoint sets \(A\) and \(X_{j}\) ~\(A\). The case weights
    \(w_{left}\) and \(w_{right}\) determine the two subgroups with
    \(w_{left,i} = w_iI(X_{j\cdot i} \in A)\) and
    \(w_{right,i} = w_iI(X_{ji} \in A)\) for all \(i = 1,...,n\) (
    \(I(·)\) denotes the indicator function).
  \item
    Recursively repeat steps 1 and 2 with modified case weights \(w_left\)
    and \(w_right\), respectively.
  \end{enumerate}
  
  from
  \url{https://eeecon.uibk.ac.at/~zeileis/papers/Hothorn+Hornik+Zeileis-2006.pdf}
  
  After step 1 is completed, any goodness of fit method can be used to
  generate the split and choose the set \(A\). Note that in this method
  the splitting is done separately from the variable selection.
  
  \chapter{Permuatations Tests Theory and Application to Conditional
  Variable
  Importance}\label{permuatations-tests-theory-and-application-to-conditional-variable-importance}
  
  \chapter{Implementation of Our
  Method}\label{implementation-of-our-method}
  
  \chapter*{Conclusion}\label{conclusion}
  \addcontentsline{toc}{chapter}{Conclusion}
  
  \setcounter{chapter}{4} \setcounter{section}{0}
  
  If we don't want Conclusion to have a chapter number next to it, we can
  add the \texttt{\{.unnumbered\}} attribute. This has an unintended
  consequence of the sections being labeled as 3.6 for example though
  instead of 4.1. The \LaTeX~commands immediately following the Conclusion
  declaration get things back on track.
  
  \subsubsection{More info}\label{more-info}
  
  And here's some other random info: the first paragraph after a chapter
  title or section head \emph{shouldn't be} indented, because indents are
  to tell the reader that you're starting a new paragraph. Since that's
  obvious after a chapter or section title, proper typesetting doesn't add
  an indent there.
  
  \appendix
  
  \chapter{The First Appendix}\label{the-first-appendix}
  
  This first appendix includes all of the R chunks of code that were
  hidden throughout the document (using the \texttt{include\ =\ FALSE}
  chunk tag) to help with readibility and/or setup.
  
  \subsubsection{In the main Rmd file:}\label{in-the-main-rmd-file}
  
  \begin{Shaded}
  \begin{Highlighting}[]
  \CommentTok{# This chunk ensures that the reedtemplates package is}
  \CommentTok{# installed and loaded. This reedtemplates package includes}
  \CommentTok{# the template files for the thesis and also two functions}
  \CommentTok{# used for labeling and referencing}
  \NormalTok{if(!}\KeywordTok{require}\NormalTok{(devtools))}
    \KeywordTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
  \NormalTok{if(!}\KeywordTok{require}\NormalTok{(reedtemplates))\{}
    \KeywordTok{library}\NormalTok{(devtools)}
    \NormalTok{devtools::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"ismayc/reedtemplates"}\NormalTok{)}
  \NormalTok{\}}
  \KeywordTok{library}\NormalTok{(reedtemplates)}
  \end{Highlighting}
  \end{Shaded}
  
  \subsubsection{\texorpdfstring{In
  \protect\hyperlink{ref_labels}{}:}{In :}}\label{in}
  
  \begin{Shaded}
  \begin{Highlighting}[]
  \CommentTok{# This chunk ensures that the reedtemplates package is}
  \CommentTok{# installed and loaded. This reedtemplates package includes}
  \CommentTok{# the template files for the thesis and also two functions}
  \CommentTok{# used for labeling and referencing}
  \NormalTok{if(!}\KeywordTok{require}\NormalTok{(devtools))}
    \KeywordTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
  \NormalTok{if(!}\KeywordTok{require}\NormalTok{(dplyr))}
      \KeywordTok{install.packages}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
  \NormalTok{if(!}\KeywordTok{require}\NormalTok{(ggplot2))}
      \KeywordTok{install.packages}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
  \NormalTok{if(!}\KeywordTok{require}\NormalTok{(reedtemplates))\{}
    \KeywordTok{library}\NormalTok{(devtools)}
    \NormalTok{devtools::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"ismayc/reedtemplates"}\NormalTok{)}
    \NormalTok{\}}
  \KeywordTok{library}\NormalTok{(reedtemplates)}
  \CommentTok{#flights <- read.csv("data/flights.csv")}
  \end{Highlighting}
  \end{Shaded}
  
  \chapter{The Second Appendix, for
  Fun}\label{the-second-appendix-for-fun}
  
  \backmatter
  
  \chapter{References}\label{references}
  
  \noindent
  
  \setlength{\parindent}{-0.20in} \setlength{\leftskip}{0.20in}
  \setlength{\parskip}{8pt}
  
  \hypertarget{refs}{}
  \hypertarget{ref-angel2000}{}
  Angel, E. (2000). \emph{Interactive computer graphics : A top-down
  approach with opengl}. Boston, MA: Addison Wesley Longman.
  
  \hypertarget{ref-angel2001}{}
  Angel, E. (2001a). \emph{Batch-file computer graphics : A bottom-up
  approach with quicktime}. Boston, MA: Wesley Addison Longman.
  
  \hypertarget{ref-angel2002a}{}
  Angel, E. (2001b). \emph{Test second book by angel}. Boston, MA: Wesley
  Addison Longman.


  % Index?

\end{document}

