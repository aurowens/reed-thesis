---
title: "Another Variable Importance Measure to Consider"
author: "Aurora Owens"
date: "November 16st, 2016"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    highlight: kate
    theme: spacelab
---

In the previous documents the variable importance measure was defined as difference in the mean squared error of the tree before permutating the variable in question and after. Here, we'll look at a variable importance measure that uses the built in deviance data in a `tree` object. 

```{r loadlib, message=FALSE, warning=FALSE}
library(MASS)
library(ggplot2)
library(dplyr)
library(tree)
```


```{r getData}

#same process as in `sampling.Rmd`
rep(0, 12) -> mu #mean of each variable

diag(12) -> sigma #creates a 12 by 12 diagonal matrix with 1's down the diagonal

sigma -> sigma1
.9 -> sigma1[1,2]
.9 -> sigma1[2,1] #adding the block correlation between the first four variables
.9 -> sigma1[1,3]
.9 -> sigma1[3,1]
.9 -> sigma1[3,2]
.9 -> sigma1[2,3]
.9 -> sigma1[1,4]
.9 -> sigma1[4,1]
.9 -> sigma1[2,4]
.9 -> sigma1[4,2]
.9 -> sigma1[4,3]
.9 -> sigma1[3,4]

#sigma1

1000 -> n #number of observations
set.seed(1)
mvrnorm(n =n, mu = mu, Sigma = sigma1) -> sim1000 #sampling from the multivariate normal 

c(5,5,2,0,-5,-5,-2,0,0,0,0,0) -> bts #these are the betas 

rnorm(1000, mean = 0, sd = .5) -> e #error terms

rep(0, 1000) -> ys #init a vector of zeros

for( i in 1:1000){ #go row by row and create the ys based on the function of e, bts, and sim1000
ys[i] <- sim1000[i,1]*bts[1]+
    sim1000[i,2]*bts[2]+ 
    sim1000[i,3]*bts[3]+ 
    sim1000[i,4]*bts[4]+ 
    sim1000[i,5]*bts[5]+ 
    sim1000[i,6]*bts[6]+
    sim1000[i,7]*bts[7]+ 
    sim1000[i,8]*bts[8]+ 
    sim1000[i,9]*bts[9]+ 
    sim1000[i,10]*bts[10]+ 
    sim1000[i,11]*bts[11]+ 
    sim1000[i,12]*bts[12] +
    e[i]
}

mvn.data <- as.data.frame(sim1000)
mvn.data$y <- ys
```

The data is the same simulated data from `sampling.Rmd`, so that there are 12 predictors where the first four are block correlated to each other with $\rho = .9$. They are related to $Y$ by the linear equation: $$Y = 5 \cdot V_1 + 5 \cdot V_2 + 2 \cdot V_3 + 0 \cdot V_4 + -5 \cdot V_5 + -5\cdot V_6 + 0\cdot V_7 + 0 \cdot ..... + E$$ Where the coefficents for variables 7-12 are all zero and $E$ ~ $N(0,\frac 1 2 )$. 

Now a tree of the relationship between $Y$ and $V1,...,V_{12}$ would look like this:

```{r}
set.seed(1)
t <- tree(y~., data = mvn.data)

plot(t)
text(t)
```

The deviance at each split is stored in the `tree` object. This can be used to formulate a variable importance. Summed over the whole tree, the variable importance, $\mathcal{V}(v)$, is defined as the total deviance from splits on that variable.  

```{r}
rep(0,12) -> base.vi
names(mvn.data[,-13]) -> name
set.seed(1)
for(i in 1:12) {
  as.data.frame(t$frame)[,c(1,3)] %>% filter(var == name[i]) %>% dplyr::summarise(sum = sum(dev)) -> base.vi[i]
}
```

The variable importance before permuation for each variable is: 

| Variable | Original VI | Linear Coefficient |
|:--------:|:-----------:|:------------------:|
|    V1    |   251886    |          5         |
|    V2    |    75891    |          5         |
|    V3    |        0    |          2         |
|    V4    |    34383    |          0         |
|    V5    |    62627    |         -5         |
|    V6    |      0      |         -5         |
|    V7    |      0      |         -2         |
|    V8    |      0      |          0         |
|    V9    |      0      |          0         |
|    V10   |      0      |          0         |
|    V11   |      0      |          0         |
|    V12   |      0      |          0         |


Now let's permute each variable with respect to it's relationship with the other 11. Then the variable importance will be calculated again, many times, and a distribution will be made to account for the variablility in tree formation and in the partitions. 

```{r functions}
intervalReturn <- function(split.cutleft){ 
  intervals <- data.frame(split.cutleft)
  intervals <- filter(intervals, split.cutleft != "")
  intervals <- dplyr::select(intervals, split.cutleft)
  intervals$split.cutleft <- gsub("<", "", intervals$split.cutleft)
  intervals$split.cutleft <- as.numeric(intervals$split.cutleft)
  return(arrange(intervals, (split.cutleft)))
}

partitionCreator <- function(i = interval, x, data) {
  p <- c(1:(1+nrow(i)))
  bins <- data.frame (bin = rep(1, nrow(data)), x = data[,x])
  for(j in 1:nrow(i)){
    bins[bins$x > i[j,1],1] <- p[j+ 1]
  }
  return(bins$bin)
}

condPermuter <- function(d2, x) {
  d2$p <- as.factor(d2$p)
  for(i in 1:length(levels(d2$p))){
   #set.seed(1)
   d2[d2$p == i, x] <- sample(d2[d2$p== i,x])
  }
  return(d2[,x])
}

VIdev<- function(t2, x){
  return(as.data.frame(t2$frame)[,c(1,3)] %>% filter(var == x) %>% dplyr::summarise(sum = sum(dev)))
}

variable.importance.dev <- function(formula1, x, d){
  t1 <- tree(formula1, data = d, y = TRUE) #This is the biggest change from CVIM_one_tree. I added this function variable.importance() to serve as a wrapper for the other functions and I created a new tree with new partitions at each interation
  #e0 <- tree.error(t1,y)
  interval <- intervalReturn(t1$frame$splits[,1])
  #permed <- data
  d$p <- partitionCreator(interval, x, d)
  d[,x] <- condPermuter(d, x)
  t2 <- tree(y ~ ., data = d, y = TRUE)
  v1 <- VIdev(t2, x)
  #rm(t1, t2)
  return(v1)
}
```

```{r}
v1vi <- rep(0,500)#init a vector for variable importance
v2vi <- rep(0,500)
v3vi <- rep(0,500)
v4vi <- rep(0,500)
v5vi <- rep(0,500)
v6vi <- rep(0,500)
v7vi <- rep(0,500)
v8vi <- rep(0,500)
v9vi <- rep(0,500)
v10vi <- rep(0,500)
v11vi <- rep(0,500)
v12vi <- rep(0,500)

p.vi <- rep(0,12)

d = mvn.data
set.seed(1)
for (i in 1:500){
v1vi[i] <- variable.importance.dev(V1~., "V1", d = mvn.data)
#d <- select(mvn.data, -p)
}

ggplot(data = as.data.frame(t(as.data.frame(v1vi))), aes(x = V1)) + 
  geom_density(fill = "#29211F")+
  ggtitle("Distribution of Variable Importance When V1 is Permuted")+
  geom_vline(xintercept =  base.vi[[1]], color = "#C27D38")

p.vi[1] <- mean(as.data.frame(t(as.data.frame(v1vi)))$V1)

set.seed(1)
for (i in 1:500){
v2vi[i] <- variable.importance.dev(V2~., "V2", d = mvn.data)
#d <- select(mvn.data, -p)
}
p.vi[2] <- mean(as.data.frame(t(as.data.frame(v2vi)))$V1)

set.seed(1)
for (i in 1:500){
v3vi[i] <- variable.importance.dev(V3~., "V3", d = mvn.data)
#d <- select(mvn.data, -p)
}
p.vi[3] <- mean(as.data.frame(t(as.data.frame(v3vi)))$V1)

set.seed(1)
for (i in 1:500){
v4vi[i] <- variable.importance.dev(V4~., "V4", d = mvn.data)
#d <- select(mvn.data, -p)
}
p.vi[4] <- mean(as.data.frame(t(as.data.frame(v4vi)))$V1)

ggplot(data = as.data.frame(t(as.data.frame(v4vi))), aes(x = V1)) + 
  geom_density(fill = "#29211F")+
  ggtitle("Distribution of Variable Importance When V4 is Permuted")+
  geom_vline(xintercept =  base.vi[[4]], color = "#C27D38")

set.seed(1)
for (i in 1:500){
v5vi[i] <- variable.importance.dev(V5~., "V5", d = mvn.data)
#d <- select(mvn.data, -p)
}
p.vi[5] <- mean(as.data.frame(t(as.data.frame(v5vi)))$V1)

set.seed(1)
for (i in 1:500){
v6vi[i] <- variable.importance.dev(V6~., "V6", d = mvn.data)
#d <- select(mvn.data, -p)
}
p.vi[6] <- mean(as.data.frame(t(as.data.frame(v6vi)))$V1)

set.seed(1)
for (i in 1:500){
v7vi[i] <- variable.importance.dev(V7~., "V7", d = mvn.data)
#d <- select(mvn.data, -p)
}
p.vi[7] <- mean(as.data.frame(t(as.data.frame(v7vi)))$V1)

set.seed(1)
for (i in 1:500){
v8vi[i] <- variable.importance.dev(V8~., "V8", d = mvn.data)
#d <- select(mvn.data, -p)
}
p.vi[8] <- mean(as.data.frame(t(as.data.frame(v8vi)))$V1)

#set.seed(1)
#for (i in 1:500){
#v9vi[i] <- variable.importance.dev(V9~., "V9", d = mvn.data)
#d <- select(mvn.data, -p)
#}
#p.vi[9] <- mean(as.data.frame(t(as.data.frame(v9vi)))$V1)

#set.seed(1)
#for (i in 1:500){
#v10vi[i] <- variable.importance.dev(V10~., "V10", d = mvn.data)
#d <- select(mvn.data, -p)
#}
#p.vi[10] <- mean(as.data.frame(t(as.data.frame(v10vi)))$V1)

#set.seed(1)
#for (i in 1:500){
#v11vi[i] <- variable.importance.dev(V11~., "V11", d = mvn.data)
#d <- select(mvn.data, -p)
#}
#p.vi[11] <- mean(as.data.frame(t(as.data.frame(v11vi)))$V1)

#set.seed(1)
#for (i in 1:500){
#v12vi[i] <- variable.importance.dev(V12~., "V12", d = mvn.data)
#d <- select(mvn.data, -p)
#}
#p.vi[12] <- mean(as.data.frame(t(as.data.frame(v12vi)))$V1)

p.vi


```

The the mean is taken of these distributions and compared with the original VI:

| Variable | Original VI | Linear Coefficient | Permuted VI |
|:--------:|:-----------:|:------------------:|:-----------:|
|    V1    |    328277   |          5         |  30177.3102 |
|    V2    |      0      |          5         |  8777.0152  |
|    V3    |     4680    |          2         |   484.4009  |
|    V4    |    48716    |          0         |   681.6613  |
|    V5    |    44573    |         -5         |   36639.53  |
|    V6    |      0      |         -5         |   58792.18  |
|    V7    |      0      |         -2         |      0      |
|    V8    |      0      |          0         |      0      |
|    V9    |      0      |          0         |      0      |
|    V10   |      0      |          0         |      0      |
|    V11   |      0      |          0         |      0      |
|    V12   |      0      |          0         |      0      |

